# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is an OCaml implementation of a Redis clone built for the CodeCrafters challenge. It supports basic Redis commands (PING, ECHO, GET, SET with expiry), master-replica replication, command propagation, and the WAIT command for synchronous replication.

## Development Workflow

**Two-Branch Strategy**: Features are developed in `with-tests` branch, then cherry-picked to `master`.

### Feature Development Cycle

1. **Run CodeCrafters tests on `master`**: Identify the next failing test/stage
2. **Switch to `with-tests` branch**: All new features start here
3. **Write tests first**: Commit unit tests for the feature
4. **Implement feature**: Commit the implementation separately
5. **Merge both in `with-tests`**: Both test and feature commits stay in the test branch
6. **Cherry-pick to `master`**: Only the feature commit gets cherry-picked to master branch
7. **Verify with CodeCrafters**: Run tests again to confirm the stage passes

This keeps `master` clean for CodeCrafters submission while maintaining comprehensive tests in `with-tests`.

Example workflow:
```bash
# 1. Identify next failing stage
git checkout master
git push origin master  # CodeCrafters runs tests automatically

# 2. Develop feature with tests
git checkout with-tests
# Write and commit tests
git commit -m "Add tests for feature X"
# Implement and commit feature
git commit -m "Implement feature X"

# 3. Cherry-pick feature to master
git checkout master
git cherry-pick <feature-commit-hash>
git push origin master  # Verify stage passes
```

## Build and Development Commands

### Building and Running
- **Build**: `dune build --build-dir /tmp/codecrafters-build-redis-ocaml`
- **Run server**: `./your_program.sh` (builds and runs)
- **Run with replication**: `./your_program.sh --port 6380 --replicaof localhost 6379`

### Testing
Tests are maintained in the `with-tests` branch (130+ tests across 4 test suites):
```bash
git checkout with-tests
dune runtest
```

Individual test suites:
- `dune exec test/resp_test.exe` - RESP parsing/serialization (47 tests)
- `dune exec test/storage_test.exe` - Storage operations and expiry (21 tests)
- `dune exec test/command_test.exe` - Command parsing (45 tests)
- `dune exec test/database_test.exe` - Database logic (17 tests)

The test suite uses Alcotest framework. Tests are kept in a separate branch to keep the main branch focused on implementation for CodeCrafters submission.

### Code Formatting
The project uses ocamlformat. Configuration is in `.ocamlformat`.

## Architecture Overview

### Module Organization

The codebase uses a layered architecture with clear separation of concerns:

**Protocol Layer** (`resp.ml`, `protocol.ml`)
- `resp.ml`: RESP protocol parsing and serialization
  - Converts between wire format (strings) and typed RESP values
  - Supports SimpleString, SimpleError, Integer, BulkString, Array, and Null types
  - `parse`: returns `(value, remaining_string) option` for incremental parsing
  - `parse_many`: parses multiple RESP values from a buffer
- `protocol.ml`: Connection handler
  - Reads from socket, buffers data, parses RESP commands
  - Invokes command handler for each complete command
  - Raises `Replication_takeover` exception after PSYNC to hand control to replication stream

**Command Layer** (`command.ml`)
- Parses RESP arrays into typed command variants: `Ping | Echo | Get | Set | InfoReplication | Replconf | Psync | Wait`
- Validates command arguments and creates structured parameter records (e.g., `set_params`, `wait_params`)
- Returns `Command.t option` - None for invalid/unknown commands

**Storage Layer** (`storage.ml`)
- In-memory key-value store using Hashtbl
- Stores values as `Resp.t` types to preserve type information
- Handles key expiry with lazy cleanup (checks expiry on `get` and `keys` operations)
- **Testability**: Uses dependency injection pattern - accepts `~current_time:float` parameter instead of calling `Unix.gettimeofday()` internally, making time-dependent behavior deterministic in tests

**Database Layer** (`database.ml`)
- Core orchestrator that encapsulates all server state
- Opaque type `t` containing: storage, config, and role variant
- Role variant ensures type safety: `Master of Replica_manager.t | Replica of { mutable replication_offset : int }`
- `execute_command`: Pure function that executes commands and returns responses
- `should_propagate_command`: Determines which commands need replication (SET but not GET/PING/ECHO)
- `handle_command`: Async wrapper that executes, propagates to replicas if needed, and sends responses

**Replication** (`replica_manager.ml`, `master_connection.ml`)
- `replica_manager.ml`: Master-side replica management
  - Tracks connected replicas with their channels and addresses
  - Batches commands before sending for performance (flushes on WAIT or batch size threshold)
  - Implements WAIT command: sends GETACK to replicas, waits for responses with timeout
  - Provides empty RDB file (base64-encoded) for PSYNC responses
- `master_connection.ml`: Replica-side master connection
  - Performs handshake: PING → REPLCONF listening-port → REPLCONF capa psync2 → PSYNC
  - Spawns background task to continuously read commands from master
  - Applies received commands to local database via `Database.execute_command`
  - Updates replication offset after each command

**Configuration** (`config.ml`)
- Parses command-line arguments: `--port <num>` and `--replicaof <host> <port>`
- Provides `Config.t` with port and optional replicaof tuple
- `Config.is_replica`: Helper to check if replicaof is configured

**Application Entry** (`main.ml`)
- Creates global mutable database reference
- Initiates master connection if running as replica (before starting server)
- Sets up Lwt server with `Lwt_io.establish_server_with_client_address`
- Command handler delegates to `Database.handle_command`
- Handles `Replication_takeover` exception to pause protocol loop during PSYNC

### Key Design Patterns

**Role Variant for Type Safety**
Instead of optional fields, the database uses a variant to ensure masters always have a replica manager and replicas always track offset:
```ocaml
type role =
  | Master of Replica_manager.t  (* Masters manage replicas *)
  | Replica of { mutable replication_offset : int }  (* Replicas track offset *)
```

**Dependency Injection for Testing**
The storage module accepts `~current_time:float` parameter instead of calling `Unix.gettimeofday()` internally. This allows tests to control time deterministically and verify expiry behavior without flakiness. See `test/storage_test.ml` for examples.

**Command Propagation Flow**
1. Client sends command to master
2. `Database.handle_command` executes via `execute_command`
3. If `should_propagate_command` returns true (e.g., SET), master calls `Replica_manager.propagate_to_replicas`
4. Replica manager batches command (RESP format) and flushes when batch is full
5. Replicas receive via `Master_connection`, apply via `Database.execute_command`, increment offset

**Protocol Takeover for PSYNC**
After PSYNC command completes, `handle_command` in `main.ml` raises `Protocol.Replication_takeover` exception. This exits the normal protocol loop and allows `Master_connection` to take over the socket for continuous replication stream reading.

**Batching for Performance**
The replica manager batches commands before sending to replicas. Commands accumulate in a buffer and are sent when:
- Batch size reaches threshold (currently implicit in implementation)
- `flush_pending` is explicitly called (e.g., before WAIT to ensure all commands are sent before checking ACKs)

## Important Implementation Details

### Replication Offset Tracking
- Masters don't track global offset; each replica tracks how many bytes it has received
- Replicas increment `replication_offset` for each command from master
- `Database.increment_offset` updates replica offset based on RESP command byte size
- WAIT command uses GETACK to query replica offsets

### RESP Parsing Strategy
The parser is optimized to minimize allocations. It uses string slicing (`String.sub`) and processes the input incrementally, returning remaining unparsed data for the next call.

### Lwt Async Patterns
- `let* () = ...` syntax requires `open Lwt.Syntax` at the top of file
- `Lwt_io` for channel-based I/O with `(ic, oc)` input/output channel pairs
- `Lwt_main.run` to execute the main event loop
- Background tasks use `Lwt.async` (e.g., master connection reader)

### Constants
`constants.ml` defines hardcoded values like:
- `master_repl_id`: Fixed replication ID returned by INFO REPLICATION
- `master_repl_offset`: Fixed offset value (always 0 in this implementation)

## Module Dependencies

```
main.ml
  ├─> database.ml (command execution, state management)
  │     ├─> storage.ml (key-value store)
  │     ├─> command.ml (command parsing)
  │     ├─> config.ml (configuration)
  │     ├─> constants.ml (fixed values)
  │     └─> replica_manager.ml (if master role)
  ├─> protocol.ml (connection handling)
  │     └─> resp.ml (RESP protocol)
  └─> master_connection.ml (if replica role)
```

## Test Structure (with-tests branch)

Tests use Alcotest framework with custom testable types for RESP values:
- **resp_test.ml**: Parsing and serialization of all RESP types, edge cases
- **storage_test.ml**: Set/get/delete operations, expiry with deterministic time
- **command_test.ml**: Parsing of all command variants, invalid input handling
- **database_test.ml**: Command execution, role detection, INFO output validation

Tests demonstrate the dependency injection pattern - passing explicit `~current_time` values to verify expiry logic without relying on real system time.
